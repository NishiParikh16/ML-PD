# -*- coding: utf-8 -*-
"""Siddhi_PD_RF_Detect_27/04/23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1O2r4p7pSU2X6mteGn_NVs5Rd0VkVlWlY
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np  
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.multioutput import MultiOutputRegressor
from xgboost.sklearn import XGBRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

dataset = pd.read_csv('/content/Dataset.csv')
dataset

X = dataset.drop(['Detectivity (Jones)'], axis = 1)
y = dataset[['Detectivity (Jones)']]

numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes('object').columns.tolist()

print(numeric_cols)
print()
print(categorical_cols)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler().fit(X[numeric_cols])

X.loc[:, (numeric_cols)] = scaler.transform(X[numeric_cols])

from sklearn.preprocessing import OneHotEncoder,LabelEncoder
from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()

X['Structure Type']=label_encoder.fit_transform(X['Structure Type'])
X['Contact Material']=label_encoder.fit_transform(X['Contact Material'])

scalery = MinMaxScaler()
scalery.fit(y)
scaler_y = scalery.transform(y)
X

X.to_csv('Scalled.csv')

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, scaler_y, test_size=0.10, random_state=3)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.10, random_state=3)

from sklearn.ensemble import RandomForestRegressor

#for_RF
model = RandomForestRegressor(n_estimators = 110, max_depth = 15, min_samples_split = 10, min_samples_leaf = 2, bootstrap = False)  

#for_XGB
#model = XGBRegressor(colsample_bytree = 1, max_depth = 30, seed = 9, subsample = 0.8, n_estimators = 90, booster = 'gbtree', eta = 0.9, min_child_weight = 5)

model.fit(X_train, y_train)

preds = model.predict(X_test)

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
num_folds = 4
cv = KFold(n_splits=num_folds, shuffle = True, random_state = 3)
scores = cross_val_score(model, X, scaler_y, cv = cv, scoring = 'neg_mean_squared_error')
mse_scores = -scores
print("Mean squared error scores: ", mse_scores)
print("Average mean squared error: {: .5f}". format(mse_scores.mean()))

pred1 = model.predict(X_train)

r2_score(y_train, pred1)

mean_absolute_error(y_train, pred1)

MSE = mean_squared_error(y_train, pred1)
MSE

import math
RMSE = np.sqrt(MSE)
RMSE

"""Validation"""

pred2 = model.predict(X_val)

mean_absolute_error(y_val, pred2)

MSE = mean_squared_error(y_val, pred2)
MSE

RMSE = np.sqrt(MSE)
RMSE

"""Testing Accuracy"""

r2_score(y_test, preds)

mean_absolute_error(y_test, preds)

MSE = mean_squared_error(y_test, preds)
MSE

RMSE = np.sqrt(MSE)
RMSE

y_test_df = pd.DataFrame(y_test)
preds_df = pd.DataFrame(preds)

y_test_df.to_csv('Actual Value.csv')

preds_df.to_csv('Predicted Value.csv')

"""**For Experimental Data**"""

test_df = pd.read_csv('/content/Test_X _Scalled.csv')
test_df

pred1 = model.predict(test_df)
pred1

df = pd.DataFrame(pred1)
predicted_results = scalery.inverse_transform(df)
predicted_results

test_Y = pd.read_csv('/content/Test_Y.csv')
test_Y

scaler_y = scalery.transform(test_Y)

mean_absolute_error(pred1, scaler_y)

MSE = mean_squared_error(pred1, scaler_y)
MSE

RMSE = np.sqrt(MSE)
RMSE

#view the feature scores

feature_scores = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)

feature_scores