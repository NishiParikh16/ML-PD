# -*- coding: utf-8 -*-
"""Siddhi_PD_RF_Resp_13/04/23.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G5a180UBoJVtufQXk-N-G02kurXwl0wc
"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np  
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.utils import shuffle
from sklearn.multioutput import MultiOutputRegressor
from xgboost.sklearn import XGBRegressor
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder, LabelEncoder
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error

dataset = pd.read_csv('/content/Dataset.csv')
dataset

#pd.plotting.scatter_matrix(dataset, alpha=0.2, figsize=(10, 10), diagonal='hist')
#plt.show()

X = dataset.drop(['Responsivity (A/W)'], axis = 1)
y = dataset[['Responsivity (A/W)']]

numeric_cols = X.select_dtypes(include=np.number).columns.tolist()
categorical_cols = X.select_dtypes('object').columns.tolist()

print(numeric_cols)
print()
print(categorical_cols)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler().fit(X[numeric_cols])

X.loc[:, (numeric_cols)] = scaler.transform(X[numeric_cols])

from sklearn.preprocessing import OneHotEncoder,LabelEncoder
from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()

X['Structure Type']=label_encoder.fit_transform(X['Structure Type'])
X['Contact Material']=label_encoder.fit_transform(X['Contact Material'])

scalery = MinMaxScaler()
scalery.fit(y)
scaler_y = scalery.transform(y)

X

X.to_csv('Scalled.csv')

f, ax = plt.subplots(figsize=(12, 12), facecolor = 'white')
corr_matrix = dataset.corr(method = 'spearman')
sns.heatmap(corr_matrix, annot =True, cmap = 'coolwarm')

import pandas as pd
from scipy.stats import spearmanr

# Load dataset
df = pd.read_csv('/content/Dataset.csv')

# Check Spearman's correlation coefficient
corr, p_value = spearmanr(dataset['Molecular weight of spacer'], dataset['Responsivity (A/W)'])
print('Spearman correlation coefficient:', corr)

# Determine relationship type
if corr > 0 and p_value < 0.05:
    print('Monotonic increasing relationship')
elif corr < 0 and p_value < 0.05:
    print('Monotonic decreasing relationship')
elif abs(corr) < 0.3:
    print('No or weak relationship')
else:
    print('Nonlinear relationship')

feature_names = list(X.columns)
feature_names

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, scaler_y, test_size=0.10, random_state=4)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=1)

from sklearn.ensemble import RandomForestRegressor

#for_RF
model = RandomForestRegressor(n_estimators = 5, max_depth = 70, min_samples_split = 2, min_samples_leaf = 3, bootstrap = False)  

#for_XGB
#model = XGBRegressor(max_depth = 84, n_estimator = 20, learning_rate = 0.3, booster = 'gbtree', seed = 4, eta = 0.64, min_child_weight = 5)

model.fit(X_train, y_train)

preds = model.predict(X_test)

from sklearn.model_selection import cross_val_score
from sklearn.model_selection import KFold
num_folds = 5
cv = KFold(n_splits=num_folds, shuffle = True, random_state = 42)
scores = cross_val_score(model, X, scaler_y, cv = cv, scoring = 'neg_mean_squared_error')
mse_scores = -scores
print("Mean squared error scores: ", mse_scores)
print("Average mean squared error: {: .5f}". format(mse_scores.mean()))

pred1 = model.predict(X_train)

r2_score(y_train, pred1)

mean_absolute_error(y_train, pred1)

MSE = mean_squared_error(y_train, pred1)
MSE

import math
RMSE = np.sqrt(MSE)
RMSE

"""Validation"""

pred2 = model.predict(X_val)

mean_absolute_error(y_val, pred2)

MSE = mean_squared_error(y_val, pred2)
MSE

RMSE = np.sqrt(MSE)
RMSE

"""Testing Accuracy"""

r2_score(y_test, preds)

mean_absolute_error(y_test, preds)

MSE = mean_squared_error(y_test, preds)
MSE

RMSE = np.sqrt(MSE)
RMSE

y_test_df = pd.DataFrame(y_test)
preds_df = pd.DataFrame(preds)

y_test_df.to_csv('Actual Value.csv')

preds_df.to_csv('Predicted Value.csv')

"""***For Experimental Data***"""

test_df = pd.read_csv('/content/Test_X _Scalled.csv')
test_df

pred1 = model.predict(test_df)
pred1

df = pd.DataFrame(pred1)
predicted_results = scalery.inverse_transform(df)
predicted_results

test_Y = pd.read_csv('/content/Test_Y.csv')
test_Y

scaler_y_test = scalery.transform

mean_absolute_error(predicted_results, test_Y)

MSE = mean_squared_error(predicted_results, test_Y)
MSE

RMSE = np.sqrt(MSE)
RMSE

"""SHAP"""

!pip install shap

import shap

explainer = shap.KernelExplainer(model = model.predict, data = test_df.head(4), link = "identity")
test_df_idx = 4

shap_value_single = explainer.shap_values(X = test_df.iloc[test_df_idx:test_df_idx+1,:], nsamples = 4)
test_df.iloc[test_df_idx:test_df_idx+1,:]
# Create the list of all labels for the drop down list
list_of_labels = y.columns.to_list()

# Create a list of tuples so that the index of the label is what is returned
tuple_of_labels = list(zip(list_of_labels, range(len(list_of_labels))))

# Create a widget for the labels and then display the widget
import ipywidgets as widgets
current_label = widgets.Dropdown(options=tuple_of_labels,
                              value=0,
                              description='Select Label:'
                              )

# Display the dropdown list (Note: access index value with 'current_label.value')
current_label

shap.initjs()
f=test_df.iloc[test_df_idx:test_df_idx+1,:]
print(f)
print(f'Current label Shown: {list_of_labels[current_label.value]}')

a=shap.force_plot(base_value = explainer.expected_value,
                shap_values = shap_value_single,
                features = test_df.iloc[test_df_idx:test_df_idx+1,:],matplotlib=True,show=False
                )

print(f'Original size: {plt.gcf().get_size_inches()}')
w, h= plt.gcf().get_size_inches()
plt.gcf().set_size_inches(h*8, h*1.5)
plt.tight_layout()
print(f'New size: {plt.gcf().get_size_inches()}')

plt.savefig('fig_tes1.png', bbox_inches='tight',dpi=500)

shap_values = explainer.shap_values(X = test_df.iloc[0:4,:], nsamples = 4)
shap.initjs()

print(f'Current Label Shown: {list_of_labels[current_label.value]}\n')
shap.summary_plot(shap_values = shap_values,
                  features = test_df.iloc[0:4,:],plot_size=(15,15),show=False
                  )

plt.savefig('grafic1.png',dpi=700)

feature_scores = pd.Series(model.feature_importances_, index=X.columns).sort_values(ascending=False)

feature_scores

from sklearn.inspection import permutation_importance

# Define the function to be used for permutation importance
def my_scorer(model, X, y):
    return model.score(X, y)

# Compute the permutation importance scores
result = permutation_importance(model, X, y, scoring=my_scorer, n_repeats=10, random_state=42)

# Get the feature importances and standard deviations
importances = result.importances_mean
std = result.importances_std

# Print the feature importances
for i, imp in enumerate(importances):
    print(f"Feature {i}: Importance {imp} +/- {std[i]}")